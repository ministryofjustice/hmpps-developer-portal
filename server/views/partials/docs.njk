
{% macro drift() %}
    <h2>Drift</h2>
    <p>
    Drift is a measure of how far behind the production version of a service is compared to the head of development of a component. 
    This is measured in real days and is calculated by comparing dates present in the build version as exposed via `/info` endpoint on the deployed service and the most recent commit to the repository. 
    </p>
    <h3>Why do we measure drift?</h3>
    <p>
    Large drift numbers suggest a stockpiling of risk and anti-agile practices. We should look to deploy frequently to ensure that we spread risk and maintain a focus on iteratively delivering value to end-users.
    </p>
    <p>A high drift number may also indicate that patching is not being pushed through the deployment pipeline. The majority of our security alerts are carried out on code hosted on the main branch or the most recently built docker image.
    Teams may address noisy security alerts but we need to ensure these fixes are pushed through to production to address security issues present in production deploys. 
    </p>
    <h3>Limitations to measuring drift</h3>
    <p>
    The way we currently measure drift does not take into account the passage of time since a deploy, so if there is a drift of 1 day, and that change is not deployed for 6 months, then the radiator would still remain green. 
    <p>
    </p>
    It is also a very rough indicator and can't take into account complexity/scale of changes, it assumes that risk builds up linearly over time.
    </p>
    <h3>Repos containing multiple components</h3>
    <p>
    The way that drift is calculated for components that reside in repos containing multiple components is handled a little bit differently. 
    This is due to how components are released independently - changes in one component should not contribute to the drift of peer components. 
    For these components we calculate drift based on the difference between the release date of the production deployment and the release date of the development deployment.     
    </p>
    <p>If one of these components is using PR based deployments then it will report drift incorrectly</p>
{% endmacro %}


{% macro staleness() %}
    <h2>Staleness</h2>
    <p>
    Staleness is a measure of whether an application is under active development. 
    This is measured in real days and is calculated by comparing the current date and the date of the most recent commit to the repository. 
    </p>
    <h3>Why do we measure staleness?</h3>
    <p>
    Large staleness numbers suggest that an application is no longer being maintained.
    </p>
    <p>A high staleness number indicates that security patching is not taking placed, suggesting that associated deployments may have known security issues.  
    </p>
    <h3>Limitations to measuring staleness</h3>
    <p>
    We cannot assume that low levels of staleness mean that security patching is taking place. It may mean that teams are focusing on delivering features - additional measures are required to determine whether this is the case.
    </p>
    <p>
    A low staleness score doesn't not guarantee that incremental delivery of value to end users is occuring. Changes may languish on development. 
    </p>
{% endmacro %}
